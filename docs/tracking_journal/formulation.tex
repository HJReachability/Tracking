% !TEX root = tracking.tex
\section{Problem Formulation \label{sec:formulation}}
In this paper we seek to simultaneously plan and track a trajectory (or path converted to a trajectory) online and in real time. 
The planning is done using a relatively simple model of the system, called the planning model. 
The tracking is done by a tracking model representing the autonomous system. 
The environment may contain static obstacles that are \textit{a priori} unknown and can be observed by the system within a limited sensing range (see Section \ref{sec:online}). 
In this section we define the tracking and planning models, as well as the goals of the paper.

\subsection{Tracking  Model}
The tracking model is a more accurate and typically higher-dimensional representation of the autonomous system dynamics than the planning model presented in Section \ref{sec:planning_model}. 
Let $\tstate$ represent the states of the tracking model. 
The evolution of the tracking model dynamics satisfy ordinary differential equation (ODE)

\begin{equation}
\begin{aligned}
\label{eq:tdyn}
\frac{d\tstate}{d\tvar} = \dot{\tstate} = \tdyn(\tstate(\tvar), \tctrl(\tvar), \dstb(\tvar)), \tvar \in [0, \thor], \\
\tstate(\tvar) \in \tset, \tctrl(\tvar) \in \tcset, \dstb(\tvar) \in \dset.
\end{aligned}
\end{equation}

We assume that the tracking model dynamics $\tdyn : \tset\ \times\ \tcset \times \dset \rightarrow \tset$ are uniformly continuous, bounded, and Lipschitz continuous in the system state $\tstate$ for a fixed control and disturbance functions $\tctrl(\cdot), \dstb(\cdot)$. The control function $\tctrl(\cdot)$ and disturbance function $\dstb(\cdot)$ are drawn from

\begin{align}
\tctrl(\cdot) \in \tcfset &= \{\phi: [0, \thor] \rightarrow \tcset: \phi(\cdot) \text{ is measurable}\},\\
\dstb(\cdot) \in \dfset &= \{\phi: [0, \thor] \rightarrow \dset: \phi(\cdot) \text{ is measurable}\}.
\end{align}


\noindent where $\tcset, \dset$ are compact and $t\in[0, \thor]$ for some $T>0$. Under these assumptions there exists a unique trajectory solving (\ref{eq:tdyn}) for a given $\tctrl(\cdot) \in \tcfset, \dstb(\cdot)\in\dfset$ \cite{Coddington84}. The trajectories of (\ref{eq:tdyn}) that solve this ODE will be denoted as $\ttraj(\tvar; \tstate, \tvar_0, \tctrl(\cdot), \dstb(\cdot))$, where $\tvar_0,\tvar \in [0, \thor]$ and $\tvar_0 \leq \tvar$. This trajectory notation represents the state of the system at time $\tvar$, given that the trajectory is initiated at state $\tstate$ and time $\tvar_0$ and applied control signal $\tctrl(\cdot)$ and disturbance signal $\dstb(\cdot)$.  These trajectories will satisfy the initial condition and the ODE (\ref{eq:tdyn}) almost everywhere:

\begin{align*}
&\frac{d}{d\tvar}\ttraj(\tvar; \tstate_0, \tvar_0, \tctrl(\cdot), \dstb(\cdot)) = \\ &\qquad \tdyn(\ttraj(\tvar; \tstate_0, \tvar_0, \tctrl(\cdot), \dstb(\cdot)), \tctrl(\tvar), \dstb(\cdot)), \\
&\ttraj(\tvar_0; \tstate_0, \tvar_0, \tctrl(\cdot), \dstb(\cdot)) = \tstate_0.
\end{align*}

Let $\tgoal \subset \tset$ represent the set of goal states, and let $\tconstr \subset \tset$ represent state constraints that must be satisfied for all time.
Often, $\tconstr$ represents the complement of obstacles that the system must avoid.

\example{We introduce a running example for illustration throughout the paper. In this example a car will have to navigate through an environment with a priori unknown obstacles ($\tconstr$) towards a goal $\tgoal$. The tracking model of the car is represented by the following five-dimensional dynamics:
\begin{equation}
\label{eq:5Ddyn}
\begin{bmatrix}
\dot x\\
\dot y\\
\dot\theta\\
\dot v\\
\dot \omega
\end{bmatrix} =
\begin{bmatrix}
v \cos \theta + \dstb_x\\
v \sin \theta + \dstb_y\\
\omega \\
a + \dstb_a\\
\alpha + \dstb_\alpha
\end{bmatrix},
\end{equation}
\noindent where $(x,y,\theta)$ represent the pose (position and heading) of the 5D car model, and $(v, \omega)$ are the speed and turn rate.
The control of the 5D model consists of the linear and angular acceleration, $(a, \alpha)$, and the disturbances are $(\dstb_x, \dstb_y, \dstb_a, \dstb_\alpha)$.
}

\subsection{Planning Model \label{sec:planning_model}}
The planning model is a simpler, lower-dimensional model of the system.
Replanning is necessary for navigation in unknown environments, so the planning model is typically one that allows a desired planning algorithm to operate in real time.
%For examples of planning models, see Section \ref{sec:results}.

Let $\pstate$ represent the state variables of the planning model, with control $\pctrl$. 
We assume that the planning states $\pstate \in \pset$ are a subset of the tracking states $\tstate \in \tset$, so that $\pset$ is a subspace within $\tset$.
This assumption is reasonable since a lower-fidelity model of a system typically involves a subset of the system's states, as with the numerical examples provided in this paper.
The dynamics of the planning model satisfy the ODE

\begin{align}
\label{eq:pdyn}
\frac{d\pstate}{d\tvar} = \dot{\pstate} = \pdyn(\pstate, \pctrl), \tvar \in [0, \thor], \quad \pstate \in \pset, \pctrl \in \pcset
\end{align}

\noindent with the analogous assumptions on continuity and boundedness as those for \eqref{eq:tdyn}.

Note that the planning model does not include a disturbance input. 
This is a key feature of FaSTrack: the treatment of disturbances is only necessary in the tracking model, which is modular with respect to any planning method. Therefore we can and will assume that the planning model (and the planning algorithm) do not consider disturbances.

Let $\goal \subset \pset$ and $\constr \subset \pset$ denote the projection of $\tgoal$ and $\tconstr$ respectively onto the subspace $\pset$.
We will assume that $\constr$ is \textit{a priori} unknown, and must be sensed as the autonomous system moves around in the environment.
Therefore, for convenience, we denote the currently known, or ``sensed'' constraints as $\constrSense(t)$.
Note that $\constrSense(t)$ depends on time, since the system may gather more information about, for example, obstacles over time.
In addition, as described throughout the paper, we will augment $\constrSense(t)$ according to the TEB between the tracking and planning models.
We denote the augmented obstacles as $\constrAug(t)$.

\example{For efficient planning we will simplify the 5D car down to a 3D planning model with the following dynamics:
\begin{equation}
\dot \pstate = 
\begin{bmatrix}
\dot {\hat x}\\
\dot {\hat y}\\
\dot {\hat \theta}
\end{bmatrix}
=
\begin{bmatrix}
\hat v \cos \hat\theta\\
\hat v \sin \hat\theta\\
\hat \omega
\end{bmatrix},
\end{equation}
\noindent where $(\hat x, \hat y, \hat\theta)$ represent the pose (position and heading) of the 3D car model. Here the speed $\hat v$ is a constant, and the turn rate $\hat \omega$ is the control. The planning model must reach its goal $\goal$ while avoiding obstacles represented by $\constr$.
}

\subsection{Goals and Approach}
Given system dynamics in \eqref{eq:tdyn}, initial state $\tstate_0$, goal states $\goal$, and constraints $\tconstr$ such that $\constr$ is \textit{a priori} unknown and determined in real time, we would like to steer the system to $\goal$ with formally guaranteed satisfaction of $\tconstr$.

To achieve this goal, FaSTrack decouples the formal guarantee of safety from the planning algorithm.
Instead of having the system, represented by the tracking model, directly plan trajectories towards $\goal$, in our framework the autonomous system (represented by the tracking model) ``chases'' the planning model of the system, which uses any planning algorithm to obtain trajectories in real time.
When the planning model of the system reaches the goal set, the autonomous system will be contained within the goal set augmented by the TEB. The ensure that the autonomous sytem has in fact reached the goal, the planning model should end within the goal set contracted by the TEB.
Safety is formally guaranteed through precomputation of a TEB along with a corresponding optimal tracking controller, in combination with augmentation of constraints based on this TEB.
An illustration of our framework applied to a navigation task is shown in Fig. \ref{fig:chasing}.