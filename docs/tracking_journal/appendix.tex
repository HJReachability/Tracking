% !TEX root = tracking.tex
\section*{Appendix}

The optimal tracking controller is obtained from the value function's spatial gradient
or $\deriv_\infty(\rstate)$

\begin{align} \label{eq:opt_ctrl_inf}
\tctrl^*(\rstate) = \arg\min_{\tctrl\in\tcset} \max_{\pctrl\in\pcset, \dstb\in\dset} \nabla\valfunc(\rstate) \cdot \rdyn(\rstate,\tctrl,\pctrl,\dstb). 
\end{align}

In order to ensure that the relative system remains within the TEB, we also note that the optimal (worst-case) planning control $\pctrl^*$ and disturbance $\dstb^*$ can also obtained from $\deriv_\infty(\rstate)$ as follows:

\begin{align} \label{eq:opt_dstb_inf}
\begin{bmatrix}
\pctrl^* \\
\dstb^*
\end{bmatrix}(\rstate) = \arg \max_{\pctrl\in\pcset, \dstb\in\dset} \nabla\valfunc_\infty(\rstate) \cdot \rdyn(\rstate,\tctrl^*,\pctrl,\dstb). 
\end{align}

In practice, we can enact the controller in \eqref{eq:opt_ctrl_inf}, but since the planning control and disturbance are \textit{a priori} unknown and are not directly controlled by the tracking model, conditions \ref{ln:plan} and \ref{ln:dist} may not hold; the result of this is only advantageous to the tracking model and will make it ``easier'' to stay within its current level set of  $\valfunc_\infty(\rstate)$. 
The smallest level set corresponding to the value $\underline\valfunc_\infty := \min_{\rstate} \valfunc_\infty(\rstate)$ can be interpreted as the smallest possible tracking error of the system. 
The TEB is given by the set 
  \begin{align} \label{eq:TEB_inf}
  \TEB_\infty = \{\rstate: \valfunc_\infty(\rstate) \le \underline\valfunc_\infty\}.
  \end{align}

Recall that we write the relative system state as $\rstate = (\estate, \astate)$, where $\estate,\astate$ are the error and auxiliary states.
Therefore, the TEB in the error state subspace is given by projecting away the auxiliary states $\astate$ in  $\TEB_\infty$:
  \begin{align}  \label{eq:TEBp_inf}
  \TEB_{\estate, \infty} = \{\estate: \exists \astate, \valfunc_\infty(\estate, \astate) \le \underline\valfunc_\infty\}. 
  \end{align}

We now formally state and prove the propositions. 
Note that an interpretation of \eqref{eq:TEBp_inf} is that $\valfunc_\infty(\rstate)$ is a control-Lyapunov function for the relative dynamics between the tracking model and the planning model.

\begin{prop}
  \label{prop:main}
  \textbf{Infinite time horizon guaranteed TEB}. Given $\tvar \ge 0$,
  
  \begin{equation}
  \forall \tvar' \ge \tvar, ~\rstate\in\TEB_\infty \Rightarrow \rtraj^*(\tvar'; \rstate, \tvar) \in \TEB_\infty,
  \end{equation}
  
  \noindent with $\rtraj^*$ defined the same way as in \eqref{eq:fin_thor_prop:here} to \eqref{eq:fin_thor_prop:there}.
  
\end{prop}


\begin{IEEEproof}
  
  Suppose that the value function converges, and define
  \begin{equation}
  \label{eq:conv_valfunc}
  \valfunc_\infty(\rstate) := \lim_{\thor\rightarrow\infty}\valfunc(\rstate, T)
  \end{equation}
  
  We first show that for all $\tvar, \tvar'$ with $\tvar' \ge \tvar$,
  \begin{equation}
  \label{eq:invariant}
  \valfunc_\infty(\rstate) \ge \valfunc_\infty(\rtraj^*(\tvar'; \rstate, \tvar)).
  \end{equation}
  
  Without loss of generality, assume $\tvar=0$. By definition, we have
  
  \begin{subequations} \label{eq:inf_thor_steps}
    \begin{align}
    \valfunc_\infty(\rstate) & = \lim_{\thor\rightarrow\infty}\max_{\tau \in [0, \thor]} \errfunc(\rtraj^*(\tau; \rstate, 0)) \label{eq:inf_thor_steps:1}\\
    &= \lim_{\thor\rightarrow\infty}\max_{\tau \in [-\tvar', \thor]} \errfunc(\rtraj^*(\tau; \rstate, -\tvar')) \label{eq:inf_thor_steps:2}\\
    &\ge \lim_{\thor\rightarrow\infty}\max_{\tau \in [0, \thor]} \errfunc(\rtraj^*(\tau; \rstate, -\tvar')) \label{eq:inf_thor_steps:3}\\
    & = \lim_{\thor\rightarrow\infty}\max_{\tau \in [0, \thor]} \errfunc(\rtraj^*(\tau; \rtraj^*(0; \rstate, -\tvar'), 0)) \label{eq:inf_thor_steps:4}\\
    & = \lim_{\thor\rightarrow\infty}\max_{\tau \in [0, \thor]} \errfunc(\rtraj^*(\tau; \rtraj^*(\tvar'; \rstate, 0), 0)) \label{eq:inf_thor_steps:5}\\
    & = \valfunc_\infty(\rtraj^*(\tvar'; \rstate, 0)) \label{eq:inf_thor_steps:6}
    \end{align}
  \end{subequations}
  
  Explanation of steps:
  \begin{itemize}
    \item \eqref{eq:inf_thor_steps:1} and \eqref{eq:fin_thor_steps:6}: by definition of value function
    \item \eqref{eq:inf_thor_steps:2}: shifting time by $-\tvar'$
    \item \eqref{eq:inf_thor_steps:3}: removing the time interval $[-\tvar',0)$ in the $\max$ operator
    \item \eqref{eq:inf_thor_steps:4}: splitting trajectory $\rtraj^*(\tau; \rstate, -\tvar')$ into two stages corresponding to time intervals $[-\tvar', 0]$ and $[0, \tau]$
    \item \eqref{eq:inf_thor_steps:5}: shifting time reference in $\rtraj^*(0; \rstate, -\tvar')$ by $\tvar'$, since dynamics are time-invariant
  \end{itemize}
  
  Now, we finish the proof as follows:
  \begin{subequations} \label{eq:inf_hor}
    \begin{align}
    \rstate \in \TEB_\infty &\Leftrightarrow \valfunc_\infty(\rstate) \le \underline\valfunc \\
    & \Rightarrow \valfunc_\infty(\rtraj^*(\tvar'; \rstate, \tvar)) \le \underline\valfunc \label{eq:inf_hor:2}\\
    & \Leftrightarrow \rtraj^*(\tvar'; \rstate, \tvar) \in \TEB_\infty,
    \end{align}
  \end{subequations}
  
  \noindent where $\eqref{eq:invariant}$ is used for the step in \eqref{eq:inf_hor:2}.
  
\end{IEEEproof} 