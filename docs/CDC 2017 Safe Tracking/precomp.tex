% !TEX root = tracking.tex
\section{Precomputation \label{sec:precomp}}

To precompute the tracking bound we set up a capture-avoid game between the real and virtual vehicles, which we then analyze using HJ reachability. In this game, the real system will try to "capture" the virtual system, while the virtual system is doing everything it can to avoid capture. By using reachability to analyze this game we will get a guaranteed bound on how far apart the two vehicles will ever be even when the virtual system is acting as inconveniently as possible.

\subsection{Relative Dynamics}
\textcolor{red}{introduce virtual dynamics, explain that it must be a subset of real system dynamics}

We now have the dynamics for the individual systems, but to set up the capture-avoid game we must first define the relative states and dynamics. We place the virtual vehicle at the origin by subtracting its states $(\vstate)$ from the real system's states $(\tstate)$. In this frame of reference $(\rstate)$ we are given the states of the real system relative to the virtual system. \textcolor{red}{incorporate disturbances here?}

Dynamics of system
\begin{equation}
\dot\vstate = \vdyn(\vstate, \vctrl, \dstb)
\end{equation}

Dynamics of trajectory
\begin{equation}
\dot\tstate = \tdyn(\tstate, \tctrl)
\end{equation}

Assume $\tstate$ is a subset of $\vstate$. 

Relative state:
\begin{equation}
\rstate = \vstate - \tvmat\tstate
\end{equation}

Relative dynamics
\begin{equation}
\dot\rstate = \rdyn(\rstate, \vctrl, \tctrl, \dstb)
\end{equation}

The relative dynamics will include the relative position states and any other relevant states such as relative angles and velocities.

\subsection{Formalizing the Capture-Avoid Game}
Now that we have the relative dynamics between the two systems we must define a metric for the tracking error bound between these systems. We do this by defining an implicit surface function as a reward function $l(\state_r)$ in the new frame of reference. Because the metric we care about is distance to the origin, this reward function can be as simple as negative distance in position space to the origin. An example can be seen in Figure \ref{fig:quad4D_example}-a, where the rings represent varying level sets of the cost function. The real vehicle will try to maximize this reward to reduce the relative distance, while the virtual vehicle will do the opposite.

\begin{figure}
	\centering
	\includegraphics[width=0.5\textwidth]{fig/quad4D_example}
	\caption{\textcolor{red}{a) reward function, b) value function, c) level sets of both mapping initial state to tracking error bound}}
	\label{fig:quad4D_example}
\end{figure} 
 
 We want to find the farthest distance (and thus highest cost) that this game will ever reach when both players are acting optimally. Therefore we want to find a mapping between the initial state of the system and the maximum cost achieved over the time horizon. This mapping is through our value function, defined as:
 \begin{equation}
 	V(\state_r)= \min_{u_2} \max_{u_1} \max_{t\in [0,T]} l(\state_r(\tau)
 	\tau \in [t, 0]
 \end{equation} 
 
 This is a modified version of the Hamilton-Jacobi formulation as described by \textcolor{red}{cite jaime, time varying reachability}. By implementing reachability analysis we solve for this value function over the time horizon. If the control authority of the real system is powerful enough to always eventually reach the virtual system, this value function will converge to an invariant solution for all time.  An example of this value function is in Figure \ref{fig:quad4D_example}-b. In the next section we will prove that the sub-level sets of this value function will map initial relative states to the guaranteed furthest possible tracking error over all time, as seen in Figure \ref{fig:quad4D_example}-c.
 
 \subsection{Tracking Error Precomputation: Guarantees and Proofs}
 
 Tracking error: $\rstate\tvind$.
 
 The goal of the system is to minimize the tracking error.
 
 The goal of the trajectory, which is a ``virtual'' vehicle, is to maximize the tracking error.
 
 Define an error function $\errfunc(\rstate)$
 
 \begin{equation}
 \valfunc(\rstate, \thor) = \max_{\vctrl(\cdot)} \min_{\tctrl(\cdot), \dstb(\cdot)} \min_{\tvar \in [-\thor, 0]} \errfunc(\rtraj(\tvar; \rstate, -\thor, \vctrl(\cdot), \tctrl(\cdot), \dstb(\cdot))) 
 \end{equation}
 
 \begin{thm}
   Let $\thor_c \ge 0$, and suppose
   
   \begin{equation}
   \label{eq:conv_valfunc}
   \valfunc_\infty(\rstate) = \valfunc(\rstate, \thor) = \valfunc(\rstate, \thor_c) ~ \forall \thor \ge \thor_c.
   \end{equation}
   
   Then $\forall \tvar_1, \tvar_2$ with $\tvar_1 \ge \tvar_2$,
   
   \begin{equation}
   \valfunc_\infty(\rstate) \le \valfunc_\infty(\rtraj(\tvar_2; \rstate, \tvar_1, \vctrl^*(\cdot), \tctrl^*(\cdot), \dstb^*(\cdot))) 
   \end{equation}
   
   \noindent where
   \begin{equation}
   \begin{aligned}
   \vctrl^*(\cdot) = \arg \max_{\vctrl(\cdot)} \min_{\tctrl(\cdot), \dstb(\cdot)} \min_{\tvar \in [-\thor_1, 0]} \errfunc(\rtraj(0; \rstate, \tvar, \vctrl(\cdot), \tctrl(\cdot), \dstb(\cdot))) \\
   \tctrl^*(\cdot) = \arg \min_{\tctrl(\cdot)} \min_{\dstb(\cdot)} \min_{t \in [-\thor_1, 0]} \errfunc(\rtraj(0; \rstate, \tvar, \vctrl(\cdot), \tctrl(\cdot), \dstb(\cdot))) \\
   \dstb^*(\cdot) = \arg \min_{\dstb(\cdot)} \min_{\tvar \in [-\thor_1, 0]} \errfunc(\rtraj(0; \rstate, \tvar, \vctrl(\cdot), \tctrl(\cdot), \dstb(\cdot))) 
   \end{aligned}
   \end{equation}
   
 \end{thm}
 
\textit{Proof:} For all $\thor \ge \thor_c$.
   
   \begin{equation}
   \begin{aligned}
   \valfunc(\rstate, \thor) &= \min_{\tvar \in [-\thor, 0]} \errfunc(\rtraj(\tvar; \rstate, -\thor, \vctrl^*(\cdot), \tctrl^*(\cdot), \dstb^*(\cdot))) \\
   &= \min \Big[ \min_{\tvar \in [-\thor_c, 0]} \errfunc(\rtraj(\tvar; \rstate, -\thor, \vctrl^*(\cdot), \tctrl^*(\cdot), \dstb^*(\cdot))), \\
   &\qquad\min_{\tvar \in [-\thor, -\thor_c]} \errfunc(\rtraj(\tvar; \rstate, -\thor, \vctrl^*(\cdot), \tctrl^*(\cdot), \dstb^*(\cdot))) \Big] \\
   \valfunc_\infty(\rstate) &= \min \Big[ \valfunc_\infty(\rtraj(-\thor_c; \rstate, -\thor, \vctrl^*(\cdot), \tctrl^*(\cdot), \dstb^*(\cdot))), \\
   &\qquad\min_{\tvar \in [-\thor, -\thor_c]} \errfunc(\rtraj(\tvar; \rstate, -\thor, \vctrl^*(\cdot), \tctrl^*(\cdot), \dstb^*(\cdot))) \Big] \\
   \valfunc_\infty(\rstate) &\le \valfunc_\infty(\rtraj(-\thor_c; \rstate, -\thor, \vctrl^*(\cdot), \tctrl^*(\cdot), \dstb^*(\cdot))) \\
   \end{aligned}
   \end{equation}
   
   Since the system dynamics are time-invariant, we can pick $\tvar_2 = -\thor_c$ without loss of generality, and $\tvar_1 = -\thor$ to obtain the desired result. \hfill $\blacksquare$
 
 \textit{Remark:} 
