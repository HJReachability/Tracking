% !TEX root = tracking.tex
\section{Online Computation \label{sec:online}}
\begin{algorithm}[bp]
	
	\caption{Online Trajectory Planning}
	\label{alg:algOnline}
	\begin{algorithmic}[1]
		\STATE Inputs: tracking error look-up table $\valfunc$, safety control look-up table $\deriv$, planning distance $\dx$
		\STATE \textbf{Initialization}: \label{ln:Istart}
		\STATE $dt = \frac{dx}{v_{max}}$ \label{ln:dt}
		\STATE $\pstate = \tstate = 0$
		\STATE $\rstate = \tstate - \ptmat\pstate$
		\STATE $\TEB = \valfunc(\rstate)$
		\STATE $\senseDist = 2\TEB+\dx$ 	\label{ln:Iend}
		
		\WHILE{planning goal is not reached}
		\STATE \textbf{Obstacles Block}: \label{ln:obsStart}
		\STATE Sense obstacles within sensing range $\senseDist$
		\STATE Expand sensed obstacles by $\TEB$ \label{ln:obsEnd}
		
		\STATE \textbf{Path Planner Block}:\label{ln:plannerStart}
		\STATE Input state $\pstate$ and augmented obstacles to path planner; output $\pstate_{next}$\label{ln:plannerEnd}
		
		\STATE \textbf{Hybrid Tracking Controller Block}:\label{ln:controllerStart}
		\STATE $\rstate_{next} = \tstate - \ptmat\pstate_{next}$
		
		\IF{$\rstate_{next}$ is near boundary $\TEB$} 
		\STATE {use safety controller:}
		\STATE {$\tctrl = \arg\min_{\tctrl}<\rdyn(\rstate_{next},\tctrl,\pctrl,\dstb),deriv\{\rstate_{next}\}>$}
		\ELSE \STATE{use performance controller} \ENDIF \label{ln:controllerEnd}
		
		\STATE \textbf{Tracking Model Block}: \label{ln:trackingStart}
		\STATE apply control $\tctrl$ to vehicle for a time step of $\dt$, save next state $\tstate_{next}$ \label{ln:trackingEnd}
		
		\STATE \textbf{Planning Model Block}:\label{ln:planningStart}
		\STATE $\pstate = \ptmat^\intercal\tstate_{next}^\intercal$
		\STATE check if $\pstate$ is at planning goal
		\STATE reset states $\tstate = \tstate_{next}, \rstate = \rstate_{next}$ \label{ln:planningEnd}
		\ENDWHILE
	\end{algorithmic}
\end{algorithm}


%\begin{enumerate}
%\item Tracking Error Block
%\begin{itemize}
%	\item Inputs: sensor information, tracking error bound
%	\item Output: augmented obstacles
%	\item Sense local environment, locate obstacles
%	\item Expand sensed obstacles by the tracking error bound
%\end{itemize}
%\item Path Planner Block
%\begin{itemize}
%	\item Inputs: virtual  state, augmented obstacles
%	\item Output: desired next virtual state
%	\item Use current virtual state and augmented obstacles to find desired next state
%\end{itemize}
%\item Hybrid Tracking Controller
%\begin{itemize}
%	\item Inputs: desired next virtual state, true model state
%	\item Output: true model control
%	\item Compute relative state
%	\item Compare relative state to tracking error bound. If the relative state is greater than dx from the tracking error bound, use the performance controller. Otherwise, use the safety controller.
%	\item Performance Controller: \SHnote{performance controller}
%	\item Safety Controller: Use controller lookup table to find the spatial gradients of the value function at that relative state. Plug in spatial gradients to the hamiltonian; find argmin control
%\end{itemize}
%\item True System Block
%\begin{itemize}
%	\item Input: control, current true system state
%	\item Output: updated true system state
%	\item Propagate true system by dt using given control
%\end{itemize}
%\item Virtual System Block
%\begin{itemize}
%	\item Input: true system state
%	\item Output: virtual system state
%	\item Project true system state onto virtual system subspace; use this as the next virtual system state
%	\item Check if goal has been reached.  If not, repeat loop
%\end{itemize}
%\end{enumerate}

\MCnote{Sampled data}
Algorithm \ref{alg:algOnline} describes the online computation. The inputs are the tracking error look-up table $\valfunc$, the safety control look-up table $\deriv$, and the planning distance $\dx$. The planning distance is the distance that the path planner (and thus the planning model) may take for each iteration of the online algorithm, and is chosen to be $0< \dx \leq \TEB$. This in turn determines the time step of each iteration (as shown on line \ref{ln:dt}): $\dt = \frac{\dx}{v_{max}}$, where $v_{max}$ is the maximum speed of the planning model.

Lines \ref{ln:Istart}-\ref{ln:Iend} initialize the computation and set the planning and tracking model states to zero. The relative state is computed (also zero in this case), and plugged into the tracking error look-up table $\valfunc$ to determine the tracking error bound $\TEB$. Note that by initializing the relative state to be zero we can use the smallest possible $\TEB$ for the entire online computation. Finally, we determine the minimum possible sensing distance for obstacle detection as $\senseDist = 2\TEB + \dx$.

The obstacle block is shown on lines \ref{ln:obsStart}-\ref{ln:obsEnd}. The sensor should detect obstacles within the sensing distance $\senseDist$ around the vehicle. The obstacle block then expands the sensed obstacles by $\TEB$, providing the planner with padded obstacles that will ensure no unsafe path can be selected. The path planner block (lines \ref{ln:plannerStart}-\ref{ln:plannerEnd}) takes in the planning model state and these augmented obstacles and outputs the next state of the planning system.

The hybrid tracking controller block (lines \ref{ln:controllerStart}-\ref{ln:controllerEnd}) first computes the updated relative state. If the relative state is nearing the tracking bound $\TEB$, the safety controller must be used to remain within the guaranteed safe bound. The safety control is found by finding the $\tctrl$ that minimizes the hamiltonian of the system.

\begin{equation}
	\tctrl = \arg\inf_{\tctrl} <\nabla\valfunc(\rstate),\rdyn(\rstate,\tctrl,\pctrl,\dstb)>
\end{equation}

The spatial gradients $\nabla\valfunc(\rstate)$ are precomputed and saved as the optimal control look-up table $\deriv$. For \SHnote{type of system} in practice this means finding the sign of the multiplier to $\tctrl$; if this multiplier is positive use the minimum $\tctrl$, otherwise use the max.

If the relative state is far from the tracking bound, a performance controller may be used. For the example in this paper the safety and performance controllers are identical.

The control is then applied in to the vehicle in the tracking block (lines \ref{ln:trackingStart}-\ref{ln:trackingEnd}) for a time period of $\dt$. The next state is saved as the tracking model's state. This then updates the planning model state in the planning model block (lines \ref{ln:planningStart}-\ref{ln:planningEnd}). We check if the planning state is at the goal, then reset all states and repeat.

