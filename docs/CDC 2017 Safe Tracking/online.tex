% !TEX root = tracking.tex
\section{Online Computation \label{sec:online}}
\begin{algorithm}[bp]
	
	\caption{Online Trajectory Planning}
	\label{alg:algOnline}
	\begin{algorithmic}[1]
		\STATE Inputs: tracking error function $\valfunc$, safety control function $\deriv$
		\STATE \textbf{Initialization}: \label{ln:Istart}
		\STATE $\pstate = \tstate = \rstate = 0$
		\STATE $\TEB_\pstate(0) = \{\pstate: \valfunc_\infty(0) \le \underline\valfunc\}$ \label{ln:Iend}
		
		\WHILE{planning goal is not reached}
		\STATE \textbf{Obstacles Block}: \label{ln:obsStart}
		\STATE $\obsAug \leftarrow \obsSense + \TEB_\pstate(0)$ \label{ln:obsEnd}
		
		\STATE \textbf{Path Planner Block}:\label{ln:plannerStart}
		\STATE $\pstate_{next} \leftarrow \plannerfunc(\pstate, \obsAug)$\label{ln:plannerEnd}
		
		\STATE \textbf{Hybrid Tracking Controller Block}:\label{ln:controllerStart}
		\STATE $\rstate_{next} = \tstate - \ptmat\pstate_{next}$
		
		\IF{$\rstate_{next}$ is on boundary $\TEB_\pstate(0)$} 
		\STATE {use safety controller:}
		\STATE {$\tctrl = \arg\min_{\tctrl}<\rdyn(\rstate_{next},\tctrl,\pctrl,\dstb),\deriv\{\rstate_{next}\}>$}
		\ELSE \STATE{use performance controller} \ENDIF \label{ln:controllerEnd}
		
		\STATE \textbf{Tracking Model Block}: \label{ln:trackingStart}
		\STATE apply control $\tctrl$ to vehicle for a time step of $\dt$, save next state as $\tstate_{next}$ \label{ln:trackingEnd}
		
		\STATE \textbf{Planning Model Block}:\label{ln:planningStart}
		\STATE $\pstate = \tpmat\tstate_{next}$
		\STATE check if $\pstate$ is at planning goal
		\STATE reset states $\tstate = \tstate_{next}, \rstate = 0$ \label{ln:planningEnd}
		\ENDWHILE
	\end{algorithmic}
\end{algorithm}


%\begin{enumerate}
%\item Tracking Error Block
%\begin{itemize}
%	\item Inputs: sensor information, tracking error bound
%	\item Output: augmented obstacles
%	\item Sense local environment, locate obstacles
%	\item Expand sensed obstacles by the tracking error bound
%\end{itemize}
%\item Path Planner Block
%\begin{itemize}
%	\item Inputs: virtual  state, augmented obstacles
%	\item Output: desired next virtual state
%	\item Use current virtual state and augmented obstacles to find desired next state
%\end{itemize}
%\item Hybrid Tracking Controller
%\begin{itemize}
%	\item Inputs: desired next virtual state, true model state
%	\item Output: true model control
%	\item Compute relative state
%	\item Compare relative state to tracking error bound. If the relative state is greater than dx from the tracking error bound, use the performance controller. Otherwise, use the safety controller.
%	\item Performance Controller: \SHnote{performance controller}
%	\item Safety Controller: Use controller lookup table to find the spatial gradients of the value function at that relative state. Plug in spatial gradients to the hamiltonian; find argmin control
%\end{itemize}
%\item True System Block
%\begin{itemize}
%	\item Input: control, current true system state
%	\item Output: updated true system state
%	\item Propagate true system by dt using given control
%\end{itemize}
%\item Virtual System Block
%\begin{itemize}
%	\item Input: true system state
%	\item Output: virtual system state
%	\item Project true system state onto virtual system subspace; use this as the next virtual system state
%	\item Check if goal has been reached.  If not, repeat loop
%\end{itemize}
%\end{enumerate}

Algorithm \ref{alg:algOnline} describes the online computation. The inputs are the tracking error function $\valfunc$, the safety control look-up function $\deriv$. Note that when discretized on a computer these functions will be look-up tables \SHnote{add Mo's citation about how this isn't a big deal to change to discrete stuff}. 

Lines \ref{ln:Istart}-\ref{ln:Iend} initialize the computation by the planning and tracking model states (and therefore the relative state) to zero. The tracking error bound in the planning frame of reference is computed using (\ref{eq:TEBp}). Note that by initializing the relative state to be zero we can use the smallest possible invariant $\TEB_\pstate$ for the entire online computation. 

The obstacle block is shown on lines \ref{ln:obsStart}-\ref{ln:obsEnd}. The sensor detects obstacles $\obsSense$ within the sensing distance around the vehicle. The minimum allowable sensing distance to guarantee safety is $\senseDist = 2\TEB + \dx$, where $\dx$ is the largest possible step in space that the planner can make in one time step. \SHnote{should we elaborate on $\dx, \dt$?} Once sensed, the obstacles $\obsSense$ are augmented by $\TEB_\pstate(0)$ using the Minkowski sum. The returned obstacles $\obsAug$ are padded by the tracking error bound to ensure that no unsafe path can be generated.

%\SHnote{The planning distance is the distance that the path planner (and thus the planning model) may take for each iteration of the online algorithm, and is chosen to be $0< \dx \leq \TEB$. This in turn determines the time step of each iteration (as shown on line \ref{ln:dt}): , where $v_{max}$ is the maximum speed of the planning model.}

 The path planner block (lines \ref{ln:plannerStart}-\ref{ln:plannerEnd}) takes in the planning model state $\pstate$ and these augmented obstacles $\obsAug$ and outputs the next state of the planning system $\pstate_{next}$. The hybrid tracking controller block (lines \ref{ln:controllerStart}-\ref{ln:controllerEnd}) first computes the updated relative state $\rstate_{next}$. If the relative state is nearing the tracking bound $\TEB_\pstate(0)$, the safety controller must be used to remain within the guaranteed safe bound. The safety control is found by finding the $\tctrl$ that minimizes the hamiltonian of the system:

\begin{equation}
	\tctrl = \arg\inf_{\tctrl} <\nabla\valfunc(\rstate_{next}),\rdyn(\rstate_{next},\tctrl,\pctrl,\dstb)>
\end{equation}

In practice, for many practical systems such as control affine systems, this minimization can be found extremely quickly by finding the sign of the multiplier to $\tctrl$; if this multiplier is positive optimal control is the minimum $\tctrl$, otherwise the optimal control is the max.

If the relative state is far from the tracking bound, a performance controller may be used. For the example in this paper the safety and performance controllers are identical, but in general this performance controller can suit the needs of the individual applications.

The control is then applied in to the vehicle in the tracking block (lines \ref{ln:trackingStart}-\ref{ln:trackingEnd}) for a time period of $\dt$. The next state is saved as the tracking model's state. This then updates the planning model state in the planning model block (lines \ref{ln:planningStart}-\ref{ln:planningEnd}). We check if the planning state is at the goal, then reset all states and repeat.

